from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.providers.slack.operators.slack_webhook import SlackWebhookOperator
from datetime import datetime, timedelta
import sys
import os
import pandas as pd
import numpy as np
from pathlib import Path
import torch
import mlflow
from sklearn.model_selection import train_test_split
import pytorch_lightning as pl

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append("/usr/local/ml4")

from src.config import Config
from src.utils.mlflow_utils import MLflowModelManager
from src.utils.inferencer import ModelInferencer
from src.train import train_model
from transformers import AutoTokenizer


os.environ['NO_PROXY'] = '*' # macì—ì„œ airflowë¡œ ì™¸ë¶€ ìš”ì²­í•  ë•Œ ì´ìŠˆê°€ ìžˆìŒ. í•˜ì—¬ í•´ë‹¹ ì½”ë“œ ì¶”ê°€ í•„ìš”

def load_production_model(**context):
    """í”„ë¡œë•ì…˜ ëª¨ë¸ ë¡œë“œ"""
    config = Config()
    model_manager = MLflowModelManager(config)
    
    model_info = model_manager.load_production_model_info()
    if model_info is None:
        raise RuntimeError("No production model found")
        
    model = model_manager.load_production_model(config.project['model_name'])
    if model is None:
        raise RuntimeError("Failed to load production model")
        
    tokenizer = AutoTokenizer.from_pretrained(model_info['params']['pretrained_model'])
    
    return model, tokenizer, model_info

def prepare_wild_data(**context):
    """in-the-wild ë°ì´í„° ì¤€ë¹„ ë° ë¶„í• """
    config = Config()
    
    # ëª¨ë¸ ë¡œë“œ
    model, tokenizer, model_info = load_production_model()
    inferencer = ModelInferencer(model, tokenizer)
    
    # ë°ì´í„° ë¡œë“œ
    data_path = Path(config.data_path) / config.dataset['in_the_wild']['wild_data_path']
    df = pd.read_csv(data_path)
    
    # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…
    text_col = config.dataset['in_the_wild']['column_mapping']['text']
    label_col = config.dataset['in_the_wild']['column_mapping']['label']
    
    print(f"Loaded {len(df)} samples from {data_path}")
    
    # ì¶”ë¡  ì‹¤í–‰
    texts = df[text_col].tolist()
    results = inferencer.predict(texts)
    
    # ë ˆì´ë¸” ë° ì‹ ë¢°ë„ ì¶”ê°€
    df[label_col] = [r['prediction'] for r in results]
    df['confidence'] = [r['confidence'] for r in results]
    
    # ë†’ì€ ì‹ ë¢°ë„(0.8 ì´ìƒ)ì˜ ë°ì´í„°ë§Œ ì„ íƒ
    df_filtered = df[df['confidence'] >= 0.8].copy()
    print(f"Selected {len(df_filtered)} samples with high confidence")
    
    # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
    test_size = config.dataset['in_the_wild']['test_size']
    train_df, val_df = train_test_split(
        df_filtered,
        test_size=test_size,
        random_state=config.project['random_state'],
        stratify=df_filtered[label_col]
    )
    
    # ë°ì´í„° ì €ìž¥
    train_path = Path(config.data_path) / config.dataset['in_the_wild']['train_data_path']
    val_path = Path(config.data_path) / config.dataset['in_the_wild']['val_data_path']
    
    train_df.to_csv(train_path, index=False)
    val_df.to_csv(val_path, index=False)
    
    print(f"Saved {len(train_df)} training samples to {train_path}")
    print(f"Saved {len(val_df)} validation samples to {val_path}")
    
    # ë°ì´í„° í†µê³„
    stats = {
        'total_samples': len(df),
        'filtered_samples': len(df_filtered),
        'train_samples': len(train_df),
        'val_samples': len(val_df),
        'positive_ratio_train': (train_df[label_col] == 1).mean(),
        'positive_ratio_val': (val_df[label_col] == 1).mean(),
    }
    
    return stats

def finetune_model(**context):
    """ë ˆì´ë¸”ë§ëœ ë°ì´í„°ë¡œ ëª¨ë¸ íŒŒì¸íŠœë‹"""
    config = Config()
    
    # ê¸°ì¡´ ì„¤ì •ì„ in-the-wild ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€ê²½
    config.project['dataset_name'] = 'in_the_wild'
    
    # ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
    train_model(config)

def evaluate_and_promote(**context):
    """ìƒˆë¡œìš´ ëª¨ë¸ í‰ê°€ ë° ìŠ¹ê²©"""
    config = Config()
    model_manager = MLflowModelManager(config)
    
    # ìµœì‹  ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    models = model_manager.list_models()
    if not models:
        raise RuntimeError("No models found")
    
    latest_model = models[-1]
    current_f1 = latest_model.get('metrics', {}).get('val_f1', 0)
    
    # ì„±ëŠ¥ ìž„ê³„ê°’ í™•ì¸
    threshold = config.mlflow.model_registry_metric_threshold
    
    if current_f1 > threshold:
        # Stagingìœ¼ë¡œ ìŠ¹ê²©
        latest_idx = len(models) - 1
        model_manager.stage_model_by_index(latest_idx, "Staging")
        print(f"New model promoted to Staging (F1: {current_f1} > threshold {threshold})")
    else:
        print(f"Model performance below threshold (F1: {current_f1} <= {threshold})")

def send_training_start_notification(**context):
    """í•™ìŠµ ì‹œìž‘ ì•Œë¦¼"""
    config = Config()
    
    message = f"""
ðŸš€ *ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œìž‘*
â€¢ ëª¨ë¸: {config.project['model_name']}
â€¢ ë°ì´í„°ì…‹: {config.project['dataset_name']}
â€¢ í•™ìŠµ ì„¤ì •:
  - Epochs: {config.models[config.project['model_name']]['training']['epochs']}
  - Batch Size: {config.models[config.project['model_name']]['training']['batch_size']}
  - Learning Rate: {config.models[config.project['model_name']]['training']['lr']}
  - Max Length: {config.models[config.project['model_name']]['training']['max_length']}
  - Optimizer: {config.models[config.project['model_name']]['training']['optimizer']}
"""
    
    # task_id ìˆ˜ì •
    notification = SlackWebhookOperator(
        task_id='slack_start_notification',  # ë³€ê²½ëœ task_id
        slack_webhook_conn_id="slack_webhook",
        message=message,
        username='ML Pipeline Bot',
        icon_emoji=':robot_face:'
    )
    
    return notification.execute(context=context)

def send_training_complete_notification(**context):
    """í•™ìŠµ ì™„ë£Œ ì•Œë¦¼"""
    config = Config()
    ti = context['task_instance']
    
    # ë°ì´í„° í†µê³„ ê°€ì ¸ì˜¤ê¸°
    data_stats = ti.xcom_pull(task_ids='prepare_wild_data')
    
    # ìµœì‹  ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    model_manager = MLflowModelManager(config)
    models = model_manager.list_models()
    if models:
        latest_model = models[-1]
        metrics = latest_model.get('metrics', {})
        
        message = f"""
âœ… *ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ*

ðŸ“Š *ë°ì´í„°ì…‹ ì •ë³´*
â€¢ ì „ì²´ ìƒ˜í”Œ ìˆ˜: {data_stats['total_samples']}
â€¢ í•„í„°ë§ëœ ìƒ˜í”Œ ìˆ˜: {data_stats['filtered_samples']}
â€¢ í•™ìŠµ ë°ì´í„°: {data_stats['train_samples']}
â€¢ ê²€ì¦ ë°ì´í„°: {data_stats['val_samples']}
â€¢ í•™ìŠµ ë°ì´í„° ê¸ì • ë¹„ìœ¨: {data_stats['positive_ratio_train']:.2%}
â€¢ ê²€ì¦ ë°ì´í„° ê¸ì • ë¹„ìœ¨: {data_stats['positive_ratio_val']:.2%}

ðŸ“ˆ *ëª¨ë¸ ì„±ëŠ¥*
â€¢ F1 Score: {metrics.get('val_f1', 0):.4f}
â€¢ Accuracy: {metrics.get('val_accuracy', 0):.4f}
â€¢ Loss: {metrics.get('val_loss', 0):.4f}

ðŸ·ï¸ *ëª¨ë¸ ì •ë³´*
â€¢ ì´ë¦„: {latest_model['run_name']}
â€¢ ìŠ¤í…Œì´ì§€: {latest_model['stage']}
â€¢ íƒ€ìž„ìŠ¤íƒ¬í”„: {latest_model['timestamp']}
"""
    else:
        message = "âŒ *ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨*\nëª¨ë¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # task_id ìˆ˜ì •
    notification = SlackWebhookOperator(
        task_id='slack_complete_notification',  # ë³€ê²½ëœ task_id
        slack_webhook_conn_id="slack_webhook",
        message=message,
        username='ML Pipeline Bot',
        icon_emoji=':robot_face:'
    )
    
    return notification.execute(context=context)

# DAG ì„¤ì •
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'model_finetuning_pipeline',
    default_args=default_args,
    description='In-the-wild ë°ì´í„°ë¥¼ ì´ìš©í•œ ëª¨ë¸ íŒŒì¸íŠœë‹ íŒŒì´í”„ë¼ì¸',
    schedule_interval='0 2 * * 1',
    catchup=False
)

# GPU ìƒíƒœ í™•ì¸
check_gpu = BashOperator(
    task_id='check_gpu',
    bash_command='nvidia-smi || echo "GPU not available"',
    dag=dag
)

# í•™ìŠµ ì‹œìž‘ ì•Œë¦¼
start_notification = PythonOperator(
    task_id='training_start_notification',  # ë³€ê²½ëœ task_id
    python_callable=send_training_start_notification,
    dag=dag
)

# ë°ì´í„° ì¤€ë¹„
prepare_data = PythonOperator(
    task_id='prepare_wild_data',
    python_callable=prepare_wild_data,
    dag=dag
)

# ëª¨ë¸ íŒŒì¸íŠœë‹
finetune_task = PythonOperator(
    task_id='finetune_model',
    python_callable=finetune_model,
    dag=dag
)

# ëª¨ë¸ í‰ê°€ ë° ìŠ¹ê²©
promote_task = PythonOperator(
    task_id='evaluate_and_promote',
    python_callable=evaluate_and_promote,
    dag=dag
)

# í•™ìŠµ ì™„ë£Œ ì•Œë¦¼
complete_notification = PythonOperator(
    task_id='training_complete_notification',  # ë³€ê²½ëœ task_id
    python_callable=send_training_complete_notification,
    dag=dag
)

# ìž‘ì—… ìˆœì„œ ì„¤ì •
start_notification >> check_gpu >> prepare_data >> finetune_task >> promote_task >> complete_notification 